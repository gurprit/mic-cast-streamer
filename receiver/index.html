<!DOCTYPE html>
<html>
<head>
  <title>Mic Receiver (Debugging)</title>
</head>
<body>
  <h1>Mic Receiver</h1>
  <audio id="sink" autoplay></audio>

  <script>
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const dest = audioCtx.createMediaStreamDestination();
    const sink = document.getElementById('sink');
    const ws = new WebSocket("wss://mic-cast-streamer.onrender.com");
    ws.binaryType = "arraybuffer";

    // Confirm AudioContext and test sound path
    audioCtx.resume().then(() => {
      console.log("AudioContext resumed");

      const testOsc = audioCtx.createOscillator();
      testOsc.type = "sine";
      testOsc.frequency.setValueAtTime(440, audioCtx.currentTime);
      testOsc.connect(dest);
      testOsc.start();
      testOsc.stop(audioCtx.currentTime + 1); // 1 sec test tone
      console.log("Test tone played");
    }).catch(err => {
      console.error("AudioContext resume failed:", err);
    });

    ws.onopen = () => {
      console.log("WebSocket connected");
    };

    ws.onmessage = async (event) => {
      console.log("Received chunk of size:", event.data.byteLength);
      try {
        const buffer = await audioCtx.decodeAudioData(event.data.slice(0));
        console.log("Decoded audio buffer:", buffer.duration, "s");

        const source = audioCtx.createBufferSource();
        source.buffer = buffer;
        source.connect(audioCtx.destination);
        source.start();
        console.log("Playback started");
      } catch (err) {
        console.error("Error decoding audio:", err);
      }
    };

    ws.onerror = (err) => {
      console.error("WebSocket error:", err);
    };

    ws.onclose = () => {
      console.warn("WebSocket closed");
    };
  </script>
</body>
</html>
